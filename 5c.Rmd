---
title: "5c -Aniket Maheshwari"
output: word_document
---

Setting up our environment and importing important libraries:
```{r}
### Clear the environment 
rm(list = ls())


### First we will set the directory of the R script 
setwd("C:/Users/anike/Desktop/Sem 1/EAS 506 Statistical Data Mining/Homework/Homework 5")


## Loading all the libraries 
library(ISLR)
library(corrplot)
library(MASS)
library(klaR)
library(leaps)
library(lattice)
library(ggplot2)
library(corrplot)
library(car)
library(caret)
library(class)
#install.packages("e1071")
library(e1071)

```

Importing the dataset: 

```{r}
# Dataset 
data('OJ')
data1 <- OJ
dim(data1)
str(data1)

```

So the OJ dataset has 1070 observation and 18 variables. Our response variable is purchase which is a binary categorical variable with 'CH' which 653 observations and 'MM' which 417 observations.

Dividing the Dataset into Test and Train Set.

```{r}
set.seed(1)
sample_size <- 800
train_indexes <- sample(seq_len(nrow(data1)), size = sample_size)
training_data <- data1[train_indexes ,]
testing_data <- data1[-train_indexes ,]

dim(training_data)
dim(testing_data)

```


The train dataset has 800 obserations and the test dataset has 270 observations.

Support Vector Machine: 
- Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier.

Support Vector classifier to the training data using "cost" = 0.01:

```{r}
svm_oj_linear <- svm(Purchase ~ ., data = training_data, kernel = "linear", cost = 0.01)
summary(svm_oj_linear)
```


So here, Support vector classifier creates 435 support vectors out of 800 training points. Out of these, 216 belong to level MM and remaining 219 belong to level CH.


Fitting Support Vector Classifier to train and test set to find train and test error:

```{r}
train_pred <- predict(svm_oj_linear, training_data)
table(training_data$Purchase, train_pred)
# train error:
mean(training_data$Purchase != train_pred) * 100
#train accuracy 
mean(training_data$Purchase == train_pred) * 100
```

So i get the training error of linear support vector machine classifier to be 17.5%

Test Error: 

```{r}
test_pred <- predict(svm_oj_linear, newdata = testing_data)
table(testing_data$Purchase, test_pred)
#test error:
mean(testing_data$Purchase != test_pred) * 100
#Test Accuracy 
mean(testing_data$Purchase == test_pred) * 100
```
So i get the testing error of linear support vector machine classifier to be 17.7% 

Tuning the classifier to find the optimal cost values. 

For this i considered value from 0.01 to 0.10.

```{r}
set.seed(2)
tune_pred <- tune(svm, Purchase ~ ., data = training_data, kernel = "linear", ranges = list(cost = 10^seq(-2, 1, by = 0.25)))
best_optimal_cost <- tune_pred$best.parameters$cost
best_optimal_cost
```

So the best optimal cost is 1.778279. I will use this optimal cost create another support vector classifer.

```{r}
svm_best_optimal_cost <- svm(Purchase ~ ., kernel = "linear", data = training_data, cost = best_optimal_cost)
summary(svm_best_optimal_cost)
```
So here, Support vector classifier creates 329 support vectors out of 800 training points. Out of these, 165 belong to level MM and remaining 164 belong to level CH.


Fitting Support Vector Classifier with the best optimal cost to train and test set to find train and test error:

Train Error:

```{r}
train_pred1 <- predict(svm_best_optimal_cost, training_data)
table(training_data$Purchase, train_pred1)
#Error:
mean(training_data$Purchase != train_pred1) * 100
#Accuracy 
mean(training_data$Purchase == train_pred1) * 100
```

So i get the training error of linear support vector machine classifier with best optimal cost to be 16.375%


Test Error: 

```{r}
test_pred1 <- predict(svm_best_optimal_cost, newdata = testing_data)
table(testing_data$Purchase, test_pred1)
#Error : 
mean(testing_data$Purchase != test_pred1) * 100 
#Accuracy 
mean(testing_data$Purchase == test_pred1) * 100
```

So i get the testing error of linear support vector machine classifier with best optimal cost to be 15.18519%


Support Vector Machine (Radial Kernel):

When we need to do some nonlinear transformations on the features Xi which transforms them into a higher dimensional space we can 
generate non-linear decision boundaries with the help of radial kernel. 

Support Vector classifier with radial kernel to the training data using "cost" = 0.01:

```{r}
set.seed(3)
svm_oj_radial <- svm(Purchase ~ ., data = training_data, kernel = "radial", gamma = if (is.vector(training_data)) 1 else 1 / ncol(training_data) , cost = 0.01)
summary(svm_oj_radial)
```

So here, Support vector classifier with radial kernel creates 634 support vectors out of 800 training points. Out of these, 315 belong to level MM and remaining 319 belong to level CH.


Fitting Support Vector Classifier with radial kernel to train and test set to find train and test error:

Train Error: 
```{r}
train_pred2 <- predict(svm_oj_radial, training_data)
table(training_data$Purchase , train_pred2)
# Error:
mean(training_data$Purchase != train_pred2) * 100
#Train Accuracy 
mean(training_data$Purchase == train_pred2) * 100

```

So i get the Training error of linear support vector machine classifier with radial kernel to be 39.375%


Test Error: 

```{r}
test_pred2 <- predict(svm_oj_radial, newdata = testing_data)
table(testing_data$Purchase , test_pred2)
# Error:
mean(testing_data$Purchase != test_pred2) * 100
#Train Accuracy 
mean(testing_data$Purchase == test_pred2) * 100

```


So i get the testing error of linear support vector machine classifier with radial kernel to be 37.77778%


Tuning the classifier to find the optimal cost values. 

For this i considered value from 0.01 to 0.10.

```{r}
set.seed(4)
tune_pred1 <- tune(svm, Purchase ~ ., data = training_data, kernel = "radial", ranges = list(cost = 10^seq(-2, 1, by = 0.25)) )
best_optimal_cost1 <- tune_pred1$best.parameters$cost
best_optimal_cost1
```


So the best optimal cost is 0.5623413. I will use this optimal cost create another support vector classifier.

```{r}
svm_best_optimal_cost1 <- svm(Purchase ~ ., kernel = "radial", data = training_data, cost = best_optimal_cost1)
summary(svm_best_optimal_cost1)
```


So here, Support vector classifier of radial kernel with best optimal cost creates 397 support vectors out of 800 training points. Out of these, 197 belong to level MM and remaining 200 belong to level CH.



Fitting Support Vector Classifier with the best optimal cost to train and test set to find train and test error:

Train Error: 

```{r}
train_pred3 <- predict(svm_best_optimal_cost1, training_data)
table(training_data$Purchase, train_pred3)
#Error:
mean(training_data$Purchase != train_pred3) * 100
#Accuracy:
mean(training_data$Purchase == train_pred3) * 100
```

So i get the training error of linear support vector machine classifier with radial kernel and best optimal cost to be 14.875%


Test Error: 
```{r}
test_pred3 <- predict(svm_best_optimal_cost1, newdata = testing_data)
table(testing_data$Purchase, test_pred3)
#Error : 
mean(testing_data$Purchase != test_pred3) * 100 
#Accuracy 
mean(testing_data$Purchase == test_pred3) * 100 
```

So i get the testing error of linear support vector machine classifier with best optimal and radial kernel cost to be 17.77778%


Support Vector Machine (Polynomial Kernel):

Support Vector classifier with Polynomial kernel of degree = 2 to the training data using "cost" = 0.01:

```{r}
set.seed(5)
svm_oj_polynomial <- svm(Purchase ~ ., data = training_data, kernel = "polynomial",degree = 2 , cost = 0.01 , scale=F)
summary(svm_oj_polynomial)
```

So here, Support vector classifier of polynomial kernel of degree = 2 creates 333 support vectors out of 800 training points. Out of these, 167 belong to level MM and remaining 166 belong to level CH.


Fitting Support Vector Classifier with polynomial kernel to train and test set to find train and test error:

Train Error: 
```{r}
train_pred4 <- predict(svm_oj_polynomial, training_data)
table(training_data$Purchase , train_pred4)
# Error:
mean(training_data$Purchase != train_pred4) * 100
#Train Accuracy 
mean(training_data$Purchase == train_pred4) * 100
```

So i get the training error of linear support vector machine classifier with polynomial kernel cost to be 16.5%

Test Error: 

```{r}
test_pred4 <- predict(svm_oj_polynomial,newdata = testing_data)
table(testing_data$Purchase , test_pred4)
#Error: 
mean(testing_data$Purchase != test_pred4) * 100
#Accuracy 
mean(testing_data$Purchase == test_pred4) * 100
```

So i get the testing error of linear support vector machine classifier with polynomial kernel cost to be 15.92593%

Tuning the classifier to find the optimal cost values. 

For this i considered value from 0.01 to 0.10.

```{r}
set.seed(6)
tune_pred3 <- tune(svm, Purchase ~ ., data = training_data, kernel = "polynomial", degree = 2,  ranges = list(cost = 10^seq(-2, 1, by = 0.25)) )
best_optimal_cost2 <- tune_pred3$best.parameters$cost
best_optimal_cost2

```

So the best optimal cost is 10 I will use this optimal cost create another support vector classifier.

```{r}
svm_best_optimal_cost2 <- svm(Purchase ~ ., kernel = "polynomial", degree = 2 ,  data = training_data, cost = best_optimal_cost2)
summary(svm_best_optimal_cost2)
```


So here, Support vector classifier of polynomial kernel with best optimal cost creates 340 support vectors out of 800 training points. Out of these, 169 belong to level MM and remaining 171 belong to level CH.

Fitting Support Vector Classifier with the best optimal cost to train and test set to find train and test error:

Train Error: 
```{r}
train_pred5 <- predict(svm_best_optimal_cost2, training_data)
table(training_data$Purchase, train_pred5)
#Error:
mean(training_data$Purchase != train_pred5) * 100
#Accuracy
mean(training_data$Purchase == train_pred5) * 100
```

So i get the training error of linear support vector machine classifier with polynomial kernel of degree = 2 and best optimal cost to be 15%


Test Error:

```{r}
test_pred5 <- predict(svm_best_optimal_cost2, newdata = testing_data)
table(testing_data$Purchase, test_pred5)
#Error : 
mean(testing_data$Purchase != test_pred5) * 100 
#Accuracy 
mean(testing_data$Purchase == test_pred5) * 100

```


So i get the Testing error of linear support vector machine classifier with polynomial kernel of degree = 2 and best optimal cost to be 18.88889%

